{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "219558d3-87af-41dd-8ea0-4034522998a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from cv2 import cv2 as cv\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "import rarfile\n",
    "import io\n",
    "import py7zr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Cropping2D, ZeroPadding2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8a6c3a-3416-44d6-ad6e-44c241c49d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://vc.ee.duth.gr/h-dibco2018/benchmark/dibco2018_Dataset.zip\n",
      "Extracted res/DIBCO18\\dibco2018_Dataset.zip\n",
      "Downloading from https://vc.ee.duth.gr/h-dibco2018/benchmark/dibco2018-GT.zip\n",
      "Extracted res/DIBCO18\\dibco2018-GT.zip\n",
      "Downloading from https://vc.ee.duth.gr/dibco2017/benchmark/DIBCO2017_Dataset.7z\n",
      "Extracted res/DIBCO17\\DIBCO2017_Dataset.7z\n",
      "Downloading from https://vc.ee.duth.gr/dibco2017/benchmark/DIBCO2017_GT.7z\n",
      "Extracted res/DIBCO17\\DIBCO2017_GT.7z\n",
      "Downloading from https://vc.ee.duth.gr/h-dibco2016/benchmark/DIBCO2016_dataset-GT.zip\n",
      "Extracted res/DIBCO16\\DIBCO2016_dataset-GT.zip\n",
      "Downloading from https://vc.ee.duth.gr/h-dibco2016/benchmark/DIBCO2016_dataset-original.zip\n",
      "Extracted res/DIBCO16\\DIBCO2016_dataset-original.zip\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('res', exist_ok=True)\n",
    "os.makedirs('res/DIBCO18', exist_ok=True)\n",
    "os.makedirs('res/DIBCO17', exist_ok=True)\n",
    "os.makedirs('res/DIBCO16', exist_ok=True)\n",
    "def fetch_data(link, location):\n",
    "    filename = os.path.join(location, link.split('/')[-1])\n",
    "    print(f\"Downloading from {link}\")\n",
    "    response = requests.get(link)\n",
    "    with open(filename, \"wb\") as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "\n",
    "    if filename.endswith(\".zip\"):\n",
    "        with zipfile.ZipFile(filename, \"r\") as file:\n",
    "            file.extractall(location)\n",
    "            print(f'Extracted {filename}')\n",
    "\n",
    "    elif filename.endswith(\".7z\"):\n",
    "        with py7zr.SevenZipFile(filename, mode=\"r\") as file:\n",
    "            file.extractall(location)\n",
    "            print(f'Extracted {filename}')\n",
    "            \n",
    "    elif filename.endswith(\".tar.gz\"):\n",
    "        with tarfile.open(filename, \"r:gz\") as file:\n",
    "            file.extractall(location)\n",
    "            print(f'Extracted {filename}')\n",
    "\n",
    "    elif filename.endswith(\".rar\"):\n",
    "        with rarfile.RarFile(filename) as file:\n",
    "            file.extractall(location)\n",
    "            print(f'Extracted {filename}')\n",
    "    else:\n",
    "        print('WARNING: Unknown file format to fetch data from')\n",
    "        \n",
    "    os.remove(filename)\n",
    "    \n",
    "fetch_data('https://vc.ee.duth.gr/h-dibco2018/benchmark/dibco2018_Dataset.zip', 'res/DIBCO18')\n",
    "fetch_data('https://vc.ee.duth.gr/h-dibco2018/benchmark/dibco2018-GT.zip', 'res/DIBCO18')\n",
    "fetch_data('https://vc.ee.duth.gr/dibco2017/benchmark/DIBCO2017_Dataset.7z', 'res/DIBCO17')\n",
    "fetch_data('https://vc.ee.duth.gr/dibco2017/benchmark/DIBCO2017_GT.7z', 'res/DIBCO17')\n",
    "fetch_data('https://vc.ee.duth.gr/h-dibco2016/benchmark/DIBCO2016_dataset-GT.zip', 'res/DIBCO16')\n",
    "fetch_data('https://vc.ee.duth.gr/h-dibco2016/benchmark/DIBCO2016_dataset-original.zip', 'res/DIBCO16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "296705c5-0ee1-4e1a-ae98-9dc35a6bde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(noisy_dirs, clean_dirs, img_size=(512, 256)):\n",
    "    noisy_images = []\n",
    "    clean_images = []\n",
    "    num_of_dirs = len(noisy_dirs)\n",
    "    if(num_of_dirs != len(clean_dirs)):\n",
    "        print('Unequal number of clean directories to noisy!')\n",
    "    else:\n",
    "        for i in range(num_of_dirs):\n",
    "            noise_files = os.listdir(noisy_dirs[i])\n",
    "            clean_files = os.listdir(clean_dirs[i])\n",
    "            for j in range(len(noise_files)):\n",
    "                noisy_img = cv.resize(cv.imread(os.path.join(noisy_dirs[i], noise_files[j])), img_size)\n",
    "                clear_img = cv.resize(cv.imread(os.path.join(clean_dirs[i], clean_files[j])), img_size)\n",
    "                noisy_img = cv.cvtColor(noisy_img, cv.COLOR_BGR2GRAY)\n",
    "                clear_img = cv.cvtColor(clear_img, cv.COLOR_BGR2GRAY)\n",
    "                noisy_img = noisy_img / 255.0\n",
    "                clear_img = clear_img / 255.0\n",
    "                noisy_img = np.expand_dims(noisy_img, axis=-1)  \n",
    "                clear_img = np.expand_dims(clear_img, axis=-1) \n",
    "                noisy_images.append(noisy_img)\n",
    "                clean_images.append(clear_img) \n",
    "    return np.array(noisy_images), np.array(clean_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56db2df8-175e-4611-81d1-834a8819c2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "184\n",
      "(89, 256, 512, 1)\n",
      "(89, 256, 512, 1)\n",
      "(56, 256, 512, 1)\n",
      "(56, 256, 512, 1)\n",
      "(39, 256, 512, 1)\n",
      "(39, 256, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "train_dirs = [\n",
    "    'res/DIBCO16/DIPCO2016_dataset',\n",
    "    'res/DIBCO17/Dataset',\n",
    "    'res/DIBCO18/dataset',\n",
    "    'res/kaggle_dirty_documents/train'\n",
    "]\n",
    "\n",
    "train_clean_dirs = [\n",
    "    'res/DIBCO16/DIPCO2016_Dataset_GT',\n",
    "    'res/DIBCO17/GT',\n",
    "    'res/DIBCO18/gt',\n",
    "    'res/kaggle_dirty_documents/train_cleaned'\n",
    "]\n",
    "\n",
    "noisy_images, clean_images = load_images(train_dirs, train_clean_dirs)\n",
    "print(len(noisy_images))\n",
    "print(len(clean_images))\n",
    "X_train, X_test, y_train, y_test = train_test_split(noisy_images, clean_images, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "print(X_train.shape)  # Expect (num_samples, 512, 256, 1)\n",
    "print(y_train.shape)  # Expect (num_samples, 512, 256, 1)\n",
    "print(X_test.shape)  # Expect (num_samples, 512, 256, 1)\n",
    "print(y_test.shape)  # Expect (num_samples, 512, 256, 1)\n",
    "print(X_val.shape)  # Expect (num_samples, 512, 256, 1)\n",
    "print(y_val.shape)  # Expect (num_samples, 512, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90906ad2-1d9e-48e7-99c2-c52c29a8b1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value in X_train: 1.0\n",
      "Min value in X_train: 0.0\n",
      "Max value in y_train: 1.0\n",
      "Min value in y_train: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Max value in X_train:\", np.max(X_train))\n",
    "print(\"Min value in X_train:\", np.min(X_train))\n",
    "print(\"Max value in y_train:\", np.max(y_train))\n",
    "print(\"Min value in y_train:\", np.min(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "867f6641-5bd2-4a7b-9424-a78cbbc14db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,    \n",
    "    height_shift_range=0.2,   \n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,           \n",
    ")\n",
    "val_test_generator = ImageDataGenerator()\n",
    "\n",
    "train_dataset = train_generator.flow(X_train, y_train, batch_size=4)\n",
    "val_dataset = val_test_generator.flow(X_test, y_test, batch_size=4)\n",
    "test_dataset = val_test_generator.flow(X_val, y_val, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f95a2fb-ba70-430a-9a54-5fac505118a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 256, 512, 64)      640       \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 256, 512, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 128, 256, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 128, 256, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128, 256, 128)     0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 128, 256, 128)     147584    \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 128, 256, 64)      73792     \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 256, 512, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256, 512, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 256, 512, 1)       577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 297,217\n",
      "Trainable params: 296,833\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation=None, padding='same', input_shape=(256, 512, 1)))\n",
    "model.add(ReLU())\n",
    "model.add(Conv2D(128, (3, 3), activation=None, padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    mse = tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n",
    "    ssim = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    return mse + 0.2 * ssim  # Adjust weight as needed\n",
    "    \n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15dfa616-369f-4e42-8eb6-304aa58e6b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 4s 168ms/step - loss: 0.2171 - mae: 0.3620 - val_loss: 0.1531 - val_mae: 0.3798 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 4s 157ms/step - loss: 0.1533 - mae: 0.3248 - val_loss: 0.0759 - val_mae: 0.2458 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 4s 155ms/step - loss: 0.0941 - mae: 0.2542 - val_loss: 0.0613 - val_mae: 0.1792 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 4s 154ms/step - loss: 0.0705 - mae: 0.1949 - val_loss: 0.0609 - val_mae: 0.1506 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 4s 155ms/step - loss: 0.0663 - mae: 0.1879 - val_loss: 0.0614 - val_mae: 0.1453 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 4s 156ms/step - loss: 0.0624 - mae: 0.1823 - val_loss: 0.0621 - val_mae: 0.1385 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0615 - mae: 0.1680 - val_loss: 0.0622 - val_mae: 0.1389 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 4s 155ms/step - loss: 0.0614 - mae: 0.1653 - val_loss: 0.0618 - val_mae: 0.1422 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 4s 155ms/step - loss: 0.0614 - mae: 0.1658 - val_loss: 0.0613 - val_mae: 0.1477 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 4s 154ms/step - loss: 0.0614 - mae: 0.1656 - val_loss: 0.0612 - val_mae: 0.1489 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 4s 155ms/step - loss: 0.0614 - mae: 0.1660 - val_loss: 0.0610 - val_mae: 0.1499 - lr: 2.5000e-04\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 4s 152ms/step - loss: 0.0614 - mae: 0.1662 - val_loss: 0.0609 - val_mae: 0.1533 - lr: 2.5000e-04\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 0.0614 - mae: 0.1660 - val_loss: 0.0607 - val_mae: 0.1542 - lr: 2.5000e-04\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 4s 154ms/step - loss: 0.0614 - mae: 0.1661 - val_loss: 0.0608 - val_mae: 0.1547 - lr: 2.5000e-04\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 4s 167ms/step - loss: 0.0613 - mae: 0.1659 - val_loss: 0.0608 - val_mae: 0.1562 - lr: 2.5000e-04\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 0.0614 - mae: 0.1658 - val_loss: 0.0606 - val_mae: 0.1560 - lr: 2.5000e-04\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 4s 174ms/step - loss: 0.0613 - mae: 0.1658 - val_loss: 0.0606 - val_mae: 0.1578 - lr: 2.5000e-04\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 4s 171ms/step - loss: 0.0613 - mae: 0.1659 - val_loss: 0.0604 - val_mae: 0.1574 - lr: 2.5000e-04\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 0.0613 - mae: 0.1661 - val_loss: 0.0605 - val_mae: 0.1605 - lr: 2.5000e-04\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 4s 172ms/step - loss: 0.0613 - mae: 0.1656 - val_loss: 0.0602 - val_mae: 0.1589 - lr: 2.5000e-04\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 4s 155ms/step - loss: 0.0613 - mae: 0.1660 - val_loss: 0.0604 - val_mae: 0.1617 - lr: 2.5000e-04\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 4s 165ms/step - loss: 0.0613 - mae: 0.1660 - val_loss: 0.0602 - val_mae: 0.1602 - lr: 2.5000e-04\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 4s 157ms/step - loss: 0.0613 - mae: 0.1657 - val_loss: 0.0601 - val_mae: 0.1622 - lr: 2.5000e-04\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 4s 167ms/step - loss: 0.0613 - mae: 0.1662 - val_loss: 0.0604 - val_mae: 0.1634 - lr: 1.2500e-04\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 4s 169ms/step - loss: 0.0613 - mae: 0.1660 - val_loss: 0.0598 - val_mae: 0.1616 - lr: 1.2500e-04\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 4s 154ms/step - loss: 0.0613 - mae: 0.1660 - val_loss: 0.0603 - val_mae: 0.1633 - lr: 1.2500e-04\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 4s 169ms/step - loss: 0.0613 - mae: 0.1658 - val_loss: 0.0602 - val_mae: 0.1631 - lr: 1.2500e-04\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 4s 154ms/step - loss: 0.0613 - mae: 0.1662 - val_loss: 0.0604 - val_mae: 0.1651 - lr: 1.2500e-04\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 4s 153ms/step - loss: 0.0613 - mae: 0.1662 - val_loss: 0.0603 - val_mae: 0.1636 - lr: 6.2500e-05\n",
      "Epoch 30/50\n",
      " 7/23 [========>.....................] - ETA: 2s - loss: 0.0690 - mae: 0.1732"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m         \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m         \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\keras\\engine\\training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1412\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1414\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1416\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\keras\\callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1107\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\keras\\utils\\tf_utils.py:607\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    605\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\keras\\utils\\tf_utils.py:601\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    599\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    600\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 601\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    603\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \n\u001b[0;32m   1138\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\testEnv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1126\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=1e-6)\n",
    "history = model.fit(train_dataset,\n",
    "         validation_data=val_dataset,\n",
    "         epochs=50,\n",
    "         batch_size=4,\n",
    "         shuffle=True,\n",
    "         verbose=1,\n",
    "        callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cf8807-7ce6-43a9-92a9-161421a52fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
